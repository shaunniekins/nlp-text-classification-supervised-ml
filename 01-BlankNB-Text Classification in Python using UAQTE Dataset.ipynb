{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1155e8a6",
   "metadata": {
    "id": "1155e8a6"
   },
   "source": [
    "<h1>Text Classification using Python (e-Participation 2.1)</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b8839",
   "metadata": {
    "id": "8b4b8839"
   },
   "source": [
    "<h1><b>INSTALLING PACKAGES</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6373bf",
   "metadata": {
    "id": "5e6373bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f7fcb",
   "metadata": {
    "id": "902f7fcb"
   },
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84126a5b",
   "metadata": {
    "id": "84126a5b"
   },
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9a11d",
   "metadata": {
    "id": "d5b9a11d"
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61388e47",
   "metadata": {
    "id": "61388e47"
   },
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4218d",
   "metadata": {
    "id": "afa4218d"
   },
   "source": [
    "<h1><b>IMPORTING LIBRARIES</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d50bb",
   "metadata": {
    "id": "6e5d50bb"
   },
   "outputs": [],
   "source": [
    "#CELL No. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebc00b",
   "metadata": {
    "id": "64ebc00b"
   },
   "source": [
    "<h1><b>LOADING AND EXPLORING THE DATASET</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb0b94",
   "metadata": {
    "id": "a3bb0b94"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faffb6b",
   "metadata": {
    "id": "5faffb6b"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77e5db",
   "metadata": {
    "id": "4a77e5db"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819804c",
   "metadata": {
    "id": "7819804c"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a0eba",
   "metadata": {
    "id": "a95a0eba"
   },
   "source": [
    "<h1><b>PRE-PROCESSING</b></h1>\n",
    "<br>\n",
    "</t>Next cell demonstrates how to preprocess the dataset by removing punctuations & special characters, cleaning texts, removing stop words, and applying lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a560e72",
   "metadata": {
    "id": "3a560e72"
   },
   "source": [
    "<h5>1. Simple Text Cleaning</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4f46a",
   "metadata": {
    "id": "40d4f46a"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab16675",
   "metadata": {
    "id": "2ab16675"
   },
   "outputs": [],
   "source": [
    "#CELL NO.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc15328",
   "metadata": {
    "id": "2cc15328"
   },
   "outputs": [],
   "source": [
    "#CELL NO.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25616588",
   "metadata": {
    "id": "25616588"
   },
   "source": [
    "<h5>2. Lexicon-based Text Preprocessing</h5><br>\n",
    " a. Stopword removal - removing insignificant words from English vocabulary using nltk. A few such words are ‘i’,’you’,’a’,’the’,’he’,’which’ etc.\n",
    "<br> b. Stemming - process of slicing the end or the beginning of words with the intention of removing affixes(prefix/suffix)\n",
    "<br> c. Lemmatization - process of reducing the word to its base form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36e6f8",
   "metadata": {
    "id": "fb36e6f8"
   },
   "outputs": [],
   "source": [
    "#CELL NO.9\n",
    "# LEXICON-BASED TEXT PROCESSING EXAMPLES\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c06c9",
   "metadata": {
    "id": "5d2c06c9"
   },
   "source": [
    "<h5>Final Preprocessing on our Dataset</h5><br>\n",
    "Applying all the preprocessing functions defined above to the data frame (df_uaqte / uaqte_balanced_dataset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8a98e",
   "metadata": {
    "id": "30f8a98e"
   },
   "outputs": [],
   "source": [
    "#CELL NO.10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59a011",
   "metadata": {
    "id": "6c59a011"
   },
   "source": [
    "<h1>FEATURE EXTRACTION</h1>\n",
    "Extracting vectors from text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff9a18",
   "metadata": {
    "id": "67ff9a18"
   },
   "source": [
    "<b>Splitting the dataset using 80:20 ratio. 80% as training set and 20% as test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da10bd",
   "metadata": {
    "id": "a6da10bd"
   },
   "outputs": [],
   "source": [
    "#CELL NO.11\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c650395",
   "metadata": {
    "id": "1c650395"
   },
   "source": [
    "<b>Extracting features/ vectors using Bag-of-words(with Tf-\n",
    "   Idf) and Word2Vec</b>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a35fa",
   "metadata": {
    "id": "c70a35fa"
   },
   "outputs": [],
   "source": [
    "#CELL NO.12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac81d28",
   "metadata": {
    "id": "cac81d28"
   },
   "outputs": [],
   "source": [
    "#CELL NO. 13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a947892",
   "metadata": {
    "id": "0a947892"
   },
   "source": [
    "<h1>TRAINING MODELS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a157a",
   "metadata": {
    "id": "248a157a"
   },
   "source": [
    "<h3>Multinomial Logistic Regression with TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fd6da",
   "metadata": {
    "id": "f50fd6da"
   },
   "outputs": [],
   "source": [
    "#CELL NO.14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76680d36",
   "metadata": {
    "id": "76680d36"
   },
   "source": [
    "<h3>Naive Bayes with TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3038e90",
   "metadata": {
    "id": "c3038e90"
   },
   "outputs": [],
   "source": [
    "#CELL NO.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87313f5b",
   "metadata": {
    "id": "87313f5b"
   },
   "source": [
    "<h3>Multinomial Logistic Regression with Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711a9a4",
   "metadata": {
    "id": "8711a9a4"
   },
   "outputs": [],
   "source": [
    "#CELL NO.16\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2c32f",
   "metadata": {
    "id": "2ca2c32f"
   },
   "source": [
    "<h3>Linear SVM with Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b566c11",
   "metadata": {
    "id": "5b566c11"
   },
   "outputs": [],
   "source": [
    "#CELL NO.17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3ce60",
   "metadata": {
    "id": "a3d3ce60"
   },
   "source": [
    "<h1>GENERATE PREDICTIONS USING THE BEST CLASSIFIER MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a5ca8",
   "metadata": {
    "id": "598a5ca8"
   },
   "outputs": [],
   "source": [
    "#CELL NO.18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f9fa4",
   "metadata": {
    "id": "810f9fa4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
